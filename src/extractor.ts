/**
 * @file Extractor for vidsrc.xyz
 * @description This module scrapes stream links for movies and TV shows with a focus on robustness and clear logging.
 */

import * as cheerio from 'cheerio';
import { ContentType } from 'stremio-addon-sdk';
// Assuming hls-utils provides HLS parsing functionality.
import { fetchAndParseHLS, ParsedHLSStream } from './hls-utils';

// --- Configuration ---
const config = {
    sourceUrl: 'https://vidsrc.xyz/embed',
    defaultBaseDomain: 'https://cloudnestra.com',
    fetchTimeout: 15000, // 15 seconds
    userAgents: [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36',
    ],
};

// --- Type Definitions ---
interface StreamResult {
    name: string;
    title: string;
    stream: string;
    referer: string;
    hlsData?: ParsedHLSStream | null;
}

interface Server {
    name: string;
    dataHash: string;
}

// --- Utilities ---

/**
 * Custom error class for detailed debugging.
 */
class ScraperError extends Error {
    constructor(message: string, public context?: Record<string, any>) {
        super(message);
        this.name = 'ScraperError';
    }
}

/**
 * Fetches a URL with a timeout.
 */
async function fetchWithTimeout(url: string, options: RequestInit = {}): Promise<Response> {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), config.fetchTimeout);
    try {
        return await fetch(url, { ...options, signal: controller.signal });
    } catch (error) {
        if (error instanceof Error && error.name === 'AbortError') {
            throw new ScraperError(`Request timed out`, { url });
        }
        throw error;
    } finally {
        clearTimeout(timeoutId);
    }
}

/**
 * Generates randomized request headers to mimic a real browser.
 */
function getRandomizedHeaders(referer: string): Record<string, string> {
    const userAgent = config.userAgents[Math.floor(Math.random() * config.userAgents.length)];
    return {
        'accept': '*/*',
        'accept-language': 'en-US,en;q=0.9',
        'Referer': `${referer}/`,
        'User-Agent': userAgent,
    };
}

/**
 * Validates if a given value is a usable URL string.
 */
function isValidUrl(url: any): url is string {
    return typeof url === 'string' && url.trim() !== '' && (url.startsWith('http') || url.startsWith('//'));
}

// --- Scraper Core Logic ---

/**
 * Parses the initial embed page to find server hashes and metadata.
 */
async function fetchAndParseServers(html: string): Promise<{ servers: Server[]; title: string; baseDomain: string }> {
    const $ = cheerio.load(html);
    const title = $('title').text().trim();
    const iframeSrc = $('iframe').attr('src') || '';

    let baseDomain = config.defaultBaseDomain;
    if (isValidUrl(iframeSrc)) {
        try {
            baseDomain = new URL(iframeSrc.startsWith('//') ? `https:${iframeSrc}` : iframeSrc).origin;
        } catch (e) {
            console.warn(`[VidSrc] Could not parse iframe URL '${iframeSrc}', falling back to default domain.`);
        }
    }

    const servers: Server[] = $('.serversList .server')
        .map((_, el) => {
            const element = $(el);
            const name = element.text().trim();
            const dataHash = element.attr('data-hash');
            return dataHash ? { name, dataHash } : null;
        })
        .get()
        .filter((s): s is Server => s !== null);

    return { servers, title, baseDomain };
}

/**
 * Extracts the stream source URL from a server's RCP (Remote Content Protocol) page.
 */
async function getStreamUrlFromServer(server: Server, baseDomain: string): Promise<string | null> {
    const rcpUrl = `${baseDomain}/rcp/${server.dataHash}`;
    const rcpRes = await fetchWithTimeout(rcpUrl, { headers: getRandomizedHeaders(baseDomain) });
    if (!rcpRes.ok) throw new ScraperError('Failed to fetch RCP page', { rcpUrl, status: rcpRes.status });

    const rcpText = await rcpRes.text();

    const initialSrcMatch = rcpText.match(/src:\s*['"]([^'"]*)['"]/);
    let streamUrl = initialSrcMatch ? initialSrcMatch[1] : null;

    if (!streamUrl) return null;

    if (streamUrl.startsWith('/prorcp/')) {
        const prorcpUrl = `${baseDomain}${streamUrl}`;
        const prorcpRes = await fetchWithTimeout(prorcpUrl, { headers: getRandomizedHeaders(baseDomain) });

        if (!prorcpRes.ok) return null; // Silently fail if the final link can't be fetched
        const prorcpText = await prorcpRes.text();

        const finalFileMatch = prorcpText.match(/file:\s*['"]((?:https?:)?\/\/[^\/'"]+\/pl\/[^'"]+?\/master\.m3u8(?:\?[^\s'"]*)?)['"]/i);
        streamUrl = finalFileMatch ? finalFileMatch[1] : null;
    }

    return streamUrl;
}

/**
 * Processes a single server to get a fully-formed stream result.
 */
async function processServer(server: Server, baseDomain: string, title: string): Promise<StreamResult | null> {
    try {
        const streamUrl = await getStreamUrlFromServer(server, baseDomain);

        if (!isValidUrl(streamUrl)) {
            console.warn(`[VidSrc] Invalid stream URL found for hash ${server.dataHash}: '${streamUrl || 'empty'}'`);
            return null;
        }

        const absoluteUrl = streamUrl.startsWith('//') ? `https:${streamUrl}` : streamUrl;
        const hlsData = await fetchAndParseHLS(absoluteUrl);

        return {
            name: `[VidSrc] ${title}`,
            title: hlsData ? `HLS - xxxp` : 'HLS Source',
            stream: absoluteUrl,
            referer: baseDomain,
            hlsData,
        };
    } catch (error) {
        const context = error instanceof ScraperError ? error.context : {};
        console.error(`[VidSrc] Failed to process server ${server.name} (${server.dataHash}): ${error instanceof Error ? error.message : 'Unknown error'}`, context);
        return null;
    }
}

// --- Main Export ---

/**
 * The main function to get stream content for a movie or series.
 */
export async function getStreamContent(id: string, type: ContentType): Promise<StreamResult[]> {
    const [imdbId, season, episode] = id.split(':');
    const url = type === 'movie'
        ? `${config.sourceUrl}/movie/${imdbId}`
        : `${config.sourceUrl}/tv/${imdbId}/${season}-${episode}`;

    console.log(`üîé Scraping for ${type}: ${id}`);

    try {
        // 1. Fetch the main embed page
        const embedRes = await fetchWithTimeout(url, { headers: getRandomizedHeaders(config.sourceUrl) });
        if (!embedRes.ok) throw new ScraperError('Failed to fetch initial embed page', {
            url,
            status: embedRes.status
        });
        const embedHtml = await embedRes.text();

        // 2. Parse out servers and metadata
        const { servers, title, baseDomain } = await fetchAndParseServers(embedHtml);
        if (servers.length === 0) {
            console.warn(`[VidSrc] No servers found on page for ${id}.`);
            return [];
        }
        console.log(`[VidSrc] Found ${servers.length} potential servers for "${title}"`);

        // 3. Process all servers in parallel, with a small delay between starting each one
        const streamPromises = servers.map((server, index) =>
            new Promise(resolve => setTimeout(() => resolve(processServer(server, baseDomain, title)), index * 200))
        );
        const results = await Promise.all(streamPromises);

        // 4. Filter out any null results from failed attempts
        const validStreams = results.filter((r): r is StreamResult => r !== null);
        console.log(`‚úÖ [VidSrc] Successfully extracted ${validStreams.length} valid streams.`);
        return validStreams;

    } catch (error) {
        const context = error instanceof ScraperError ? error.context : {};
        console.error(`‚ùå [VidSrc] Critical error scraping for ${id}: ${error instanceof Error ? error.message : 'Unknown error'}`, context);
        return []; // Always return an array, even on failure
    }
}
